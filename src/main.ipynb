{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Run the following commands in an external terminal for the uninstall process to work properly\n",
    "#py -3.8 -m pip uninstall stable-baselines3\n",
    "#py -3.8 -m pip uninstall gymnasium\n",
    "#py -3.8 -m pip uninstall nes-py\n",
    "#py -3.8 -m pip uninstall gym-super-mario-bros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of libaries, websites, and other resources referenced for this project:\n",
    "\n",
    "Markdown Guide - Basic Syntax (for documentation): https://www.markdownguide.org/basic-syntax/ <br>\n",
    "\n",
    "OpenAI's Gym library: https://github.com/openai/gym <br>\n",
    "\n",
    "nes-py, an NES emulator and OpenAI Gym interface: https://github.com/Kautenja/nes-py <br>\n",
    "gym-super-mario-bros, an OpenAI Gym environment for Super Mario Bros. using nes-py: https://github.com/Kautenja/gym-super-mario-bros <br>\n",
    "\n",
    "PyTorch, a machine learning library for Python: https://pytorch.org/ <br>\n",
    "Stable Baselines3, an RL algorithms library for PyTorch: https://github.com/DLR-RM/stable-baselines3 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch (stable version) locally on Windows w/ GPU acceleration via pip\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force downgrade wheel & setuptools in order for gym v21 to install properly\n",
    "%pip install wheel==0.38.4 setuptools==66.0.0\n",
    "\n",
    "# Install Stable Baselines3 library version 1.8.0 (last version to include & use gym v21)\n",
    "%pip install stable-baselines3==1.8.0 --no-cache-dir\n",
    "\n",
    "# Upgrade wheel & setuptools back to their latest versions\n",
    "%pip install --upgrade wheel setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gym-super-mario-bros (includes nes-py, requires gym v21)\n",
    "# Note: nes-py requires MSVC build tools to install\n",
    "%pip install gym-super-mario-bros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "\n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-v0\") # Make gym environment with SMB1 in standard ROM mode\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT) # Set joypad wrapper; restrict to SIMPLE_MOVEMENT (only 7 actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default code from gym-super-mario-bros repository - will run w/ random inputs & no machine learning AI\n",
    "done = True\n",
    "for step in range(5000):\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproccesing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes the actual environment\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "\n",
    "# simplifies the movement to only 7 options\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "# removes color from the environment to help with processing speed\n",
    "env = GrayScaleObservation(env, keep_dim = True)\n",
    "\n",
    "# wraps the environment in a dummy vector environment so that they can be stacked\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# stacks 10 frames ontop of each other, so the AI can make decisions based on its previous locations\n",
    "env = VecFrameStack(env, 10, channels_order = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes sure the environment has been properly reset to the start\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Stack Vizualization code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps forward in the environment, doing action 5 [Jump]\n",
    "# this is here purely to visualize what the AI sees when\n",
    "# given stacked frames\n",
    "state, reward, done, info = env.step([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,16))\n",
    "for idx in range(state.shape[3]):\n",
    "    plt.subplot(1,10,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code For Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLogCallBack(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose = 1):\n",
    "        super(TrainLogCallBack, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def _init_callback(self):\n",
    "        if self.save_path != None:\n",
    "            os.makedirs(self.save_path, exist_ok = True)\n",
    "    \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'E:/4444_AI_files/Train/'\n",
    "LOG_DIR = 'E:/4444_AI_files/Log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just creating an actual instance of the callback created above\n",
    "# saves the model every 10,000 steps\n",
    "callback = TrainLogCallBack(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the actual PPO model\n",
    "# (Why can't getting the data be this easy :/ )\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, n_steps = 512)\n",
    "\n",
    "#this should say using cuda device at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what actually trains the model\n",
    "# it runs for 1 billion timesteps [maybe a bit overkill]\n",
    "# ie, the AI will see 1 billion frames before it ends\n",
    "# it uses the callback instance created above\n",
    "model.learn(total_timesteps = 1000000000, callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('thisisastatesmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Created Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the final model\n",
    "model = PPO.load('E:/4444_AI_files/Train/best_model_1000000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "while True:\n",
    "    action, _state = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
